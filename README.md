# ðŸŽ“ Prevendo Risco de Defasagem com Machine Learning (Datathon 2025)

## 1. VisÃ£o Geral do Projeto 
**Objetivo:** PrevisÃ£o de Risco com Machine Learning.
Quais padrÃµes nos indicadores permitem identificar alunos em risco antes de queda no desempenho ou aumento da defasagem? 

ConstruÃ­mos um modelo preditivo que mostra uma **probabilidade do aluno ou aluna entrar em risco de defasagem**.

**SoluÃ§Ã£o Proposta:** Uma pipeline completa de Machine Learning (MLOps) que vai desde a ingestÃ£o dos dados brutos atÃ© o deploy de uma API em produÃ§Ã£o e um Dashboard interativo.

### Stack TecnolÃ³gica
*   **Linguagem:** Python 3.12
*   **Machine Learning:** scikit-learn, pandas, numpy, scipy
*   **API:** FastAPI (com autenticaÃ§Ã£o JWT)
*   **Dashboard:** Streamlit (com monitoramento de Data Drift)
*   **SerializaÃ§Ã£o:** joblib
*   **Testes:** pytest (com cobertura de cÃ³digo)
*   **Empacotamento:** Docker & Docker Compose
*   **CI/CD:** GitHub Actions
*   **Deploy Cloud:** Render (API) + Streamlit Cloud (Dashboard)

---

## 2. Estrutura do Projeto

A organizaÃ§Ã£o do repositÃ³rio segue as melhores prÃ¡ticas de Engenharia de ML:

```
prj-datathon/
â”œâ”€â”€ .github/workflows/      # CI Pipeline (GitHub Actions)
â”œâ”€â”€ app/                    # CÃ³digo da API (FastAPI)
â”‚   â”œâ”€â”€ auth.py             # LÃ³gica de AutenticaÃ§Ã£o JWT
â”‚   â”œâ”€â”€ main.py             # Entrypoint da API
â”‚   â”œâ”€â”€ models/             # Modelos Treinados (.joblib)
â”‚   â”œâ”€â”€ router.py           # Endpoints (/predict, /token)
â”‚   â”œâ”€â”€ schemas.py          # Modelos Pydantic (ValidaÃ§Ã£o)
â”‚   â””â”€â”€ state.py            # Gerenciamento de Estado (Lifespan)
â”œâ”€â”€ dashboard/              # CÃ³digo do Frontend (Streamlit)
â”‚   â””â”€â”€ app.py              # AplicaÃ§Ã£o Interativa
â”œâ”€â”€ data/                   # Dados (GitIgnored, exceto reference_data.csv)
â”œâ”€â”€ notebooks/              # Jupyter Notebooks (EDA e Testes)
â”œâ”€â”€ scripts/                # Scripts Auxiliares (ExtraÃ§Ã£o de Dados)
â”œâ”€â”€ src/                    # Core do ML (Pacote Python)
â”‚   â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes Globais (Caminhos, VariÃ¡veis)
â”‚   â”œâ”€â”€ data_loader.py      # Carregamento e Limpeza
â”‚   â”œâ”€â”€ evaluation.py       # AvaliaÃ§Ã£o do Modelo (MÃ©tricas e RelatÃ³rios)
â”‚   â”œâ”€â”€ feature_engineering.py # CriaÃ§Ã£o de Features Temporais
â”‚   â”œâ”€â”€ modeling.py         # Wrapper do Modelo (RandomForest)
â”‚   â”œâ”€â”€ preprocessing.py    # Pipeline de TransformaÃ§Ã£o
â”‚   â””â”€â”€ train_pipeline.py   # Script de Treinamento
â”œâ”€â”€ tests/                  # Testes UnitÃ¡rios e de IntegraÃ§Ã£o
â”œâ”€â”€ Dockerfile              # Receita da Imagem Docker
â”œâ”€â”€ docker-compose.yml      # OrquestraÃ§Ã£o Local
â”œâ”€â”€ pyproject.toml          # Gerenciamento de DependÃªncias
â”œâ”€â”€ requirements.txt        # Lista de Libs (Pip)
â””â”€â”€ README.md               # DocumentaÃ§Ã£o Oficial
```

---

## 3. InstruÃ§Ãµes de Deploy (Como subir o ambiente)

### OpÃ§Ã£o A: Rodando Localmente com Docker (Recomendado)
A maneira mais fÃ¡cil de testar a API isoladamente com ambiente containerizado.

**PrÃ©-requisitos:** Docker e Docker Compose instalados.

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/ManoelSa/prj-datathon.git
    cd prj-datathon
    ```
2.  **Configure as VariÃ¡veis de Ambiente:**
    Crie um arquivo `.env` na raiz:
    ```env
    APP_USER=admin
    APP_PASS=admin123
    SECRET_KEY=sua_chave_secreta_super_segura
    API_URL=http://api:8000 # Para o docker-compose se conversarinternamente
    ```
3.  **Suba os contÃªineres:**
    ```bash
    docker-compose up --build
    ```
    *   **API:** DisponÃ­vel em `http://localhost:8000/docs`

### OpÃ§Ã£o B: Rodando Localmente com Python (Venv)

1.  **Crie e ative o ambiente virtual:**
    ```bash
    python -m venv venv
    # Windows: venv\Scripts\activate
    # Linux/Mac: source venv/bin/activate
    ```
2.  **Instale as dependÃªncias:**
    ```bash
    pip install . # Instala o projeto via pyproject.toml
    ```
3.  **Treine o Modelo (Gerar o .joblib):**
    ```bash
    python -m src.train_pipeline
    ```
4.  **Rode a API:**
    ```bash
    uvicorn app.main:app --reload
    ```
5.  **Rode o Dashboard (em outro terminal):**
    ```bash
    streamlit run dashboard/app.py
    ```

---

## 4. Exemplos de Chamadas Ã  API

A API Ã© protegida por token JWT. O fluxo Ã©: **Login -> Token -> PrediÃ§Ã£o**.

### 1. AutenticaÃ§Ã£o (Obter Token)
**POST** `/token`
```bash
curl -X POST "http://localhost:8000/token" \
     -H "Content-Type: application/x-www-form-urlencoded" \
     -d "username=admin&password=admin123"
```
**Resposta:**
```json
{"access_token": "eyJhbGciOi...", "token_type": "bearer"}
```

### 2. PrediÃ§Ã£o (Analisar Risco)
**POST** `/predict` (Use o token no Header)
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Authorization: Bearer SEU_TOKEN_AQUI" \
     -H "Content-Type: application/json" \
     -d '{
       "IAA": 5.5, "IEG": 6.2, "IPS": 7.0, "IDA": 8.0, 
       "IPP": 4.5, "IPV": 6.1, "IAN": 5.0, "INDE": 6.5, 
       "Defasagem": 0.0
     }'
```
**Resposta:**
```json
{
  "prediction": 0,
  "probability": 0.12,
  "status": "Baixo Risco"
}
```

---

## 5. Etapas do Pipeline de Machine Learning

O pipeline de dados (`src/`) foi desenhado para ser modular e reproduzÃ­vel:

1.  **IngestÃ£o e Limpeza (`data_loader.py`):**
    *   Carrega mÃºltiplas abas do Excel (2022, 2023, 2024).
    *   Padroniza nomes de colunas e remove caracteres invÃ¡lidos.
    *   Converte tipos numÃ©ricos e trata nulos.

2.  **Engenharia de Features (`feature_engineering.py`):**
    *   **Abordagem Temporal:** O modelo nÃ£o olha apenas para um ano isolado.
    *   Criamos pares de **(Ano T -> Ano T+1)**.
    *   *Features (X):* Indicadores do Ano T (ex: IAA 2022).
    *   *Target (Y):* Risco de Defasagem no Ano T+1 (Defasagem < 0).

3.  **PrÃ©-processamento (`preprocessing.py`):**
    *   Pipeline do Scikit-Learn.
    *   `SimpleImputer`: Preenche valores faltantes com a mediana.
    *   `StandardScaler`: Normaliza as escalas dos indicadores (0-10) para evitar viÃ©s.

4.  **Treinamento e SeleÃ§Ã£o de Modelo (`train_pipeline.py`):**
    *   **Algoritmo:** Random Forest Classifier (Robustez e explicabilidade).
    *   **MÃ©trica de AvaliaÃ§Ã£o:** ROC-AUC (Melhor para classes desbalanceadas).
    *   O modelo final Ã© salvo em `models/risk_model.joblib`.

5.  **Monitoramento (`dashboard/app.py`):**
    *   Compara a distribuiÃ§Ã£o dos dados de Treino (ReferÃªncia) com os dados novos chegando na API (ProduÃ§Ã£o).
    *   Usa Teste KS (Kolmogorov-Smirnov) para alertar sobre **Data Drift** (mudanÃ§a de padrÃ£o no comportamento dos alunos).
